{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df37a9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "from scipy.optimize import minimize_scalar\n",
    "import os\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "garbage_limit = 28\n",
    "\n",
    "def remove_rank(x):\n",
    "    return x[x[:5].find(')')+2 if x[:5].find(')')>0 else 0:]\n",
    "\n",
    "def weight(weeks_ago, game_count, max_games, decay=1/3):\n",
    "    game_weight = game_count / max_games\n",
    "    time_weight = 1/(weeks_ago**decay)\n",
    "    return (game_weight*time_weight)**(1/2)\n",
    "\n",
    "def get_schedule(soup, week, hfa = 3, decay = 1/3):\n",
    "    \n",
    "    items = []\n",
    "    for item in soup.find_all('td'):\n",
    "        items.append(item.get_text())\n",
    "\n",
    "    weeks = items[0::10]\n",
    "    dates = items[1::10]\n",
    "    times = items[2::10]\n",
    "    days = items[3::10]\n",
    "    winners = items[4::10]\n",
    "    winner_pts = items[5::10]\n",
    "    location = items[6::10]\n",
    "    loser = items[7::10]\n",
    "    loser_pts = items[8::10]\n",
    "    notes = items[9::10]\n",
    "\n",
    "    zipped = list(zip(weeks, winners, winner_pts, location, loser, loser_pts))\n",
    "    schedule_raw = pd.DataFrame(zipped, columns=['week', 'winner', 'winner_pts', 'location', 'loser','loser_pts',])\n",
    "\n",
    "    schedule_raw['week'] = schedule_raw['week'].astype(str).astype(int)\n",
    "    schedule_raw = schedule_raw[schedule_raw['week']<=week]\n",
    "    schedule_raw['winner_pts'] = pd.to_numeric((schedule_raw['winner_pts'].astype(str)), errors='coerce')\n",
    "    schedule_raw['loser_pts'] = pd.to_numeric((schedule_raw['loser_pts'].astype(str)), errors='coerce')\n",
    "    schedule_raw = schedule_raw.dropna() \n",
    "    schedule_raw = schedule_raw[((schedule_raw['winner_pts'] + schedule_raw['loser_pts']) > 0)]\n",
    "\n",
    "    conditions = [schedule_raw['location'] == '@', schedule_raw['location'] == '', schedule_raw['location'] == 'N']\n",
    "    location_text = ['away', 'home', 'neutral']\n",
    "    \n",
    "    location_adjustment = [hfa, -hfa, 0]\n",
    "    schedule_raw['location'] = np.select(conditions, location_text)\n",
    "    schedule_raw['location_adjustment'] = np.select(conditions, location_adjustment)\n",
    "\n",
    "    schedule_raw['winner'] = schedule_raw['winner'].apply(remove_rank)\n",
    "    schedule_raw['loser'] = schedule_raw['loser'].apply(remove_rank)\n",
    "\n",
    "    schedule_raw['margin'] = schedule_raw['winner_pts'] - schedule_raw['loser_pts']\n",
    "    schedule_raw['true_margin'] = schedule_raw['margin'] + schedule_raw['location_adjustment']\n",
    "    schedule_raw['true_margin'] = schedule_raw['true_margin'].apply(lambda x : garbage_limit if x>garbage_limit else x)\n",
    "    \n",
    "    schedule_raw = schedule_raw.drop_duplicates()\n",
    "\n",
    "    team_count = pd.concat([schedule_raw['winner'], schedule_raw['loser']], axis = 0, ignore_index=True).value_counts().to_frame()\n",
    "    team_count['team'] = team_count.index\n",
    "    team_count.columns = ['games', 'team']\n",
    "    team_count.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    schedule_raw = pd.merge(schedule_raw, team_count, left_on = 'winner', right_on = 'team', how = 'left')\n",
    "    schedule_raw = pd.merge(schedule_raw, team_count, left_on = 'loser', right_on = 'team', how = 'left', suffixes = ['_winner', '_loser'])\n",
    "    schedule_raw['total_games'] = schedule_raw['games_winner'] + schedule_raw['games_loser']\n",
    "    schedule_raw['weeks_ago'] = (max(schedule_raw['week'])+1) - schedule_raw['week']\n",
    "\n",
    "    max_games = max(schedule_raw['total_games'])\n",
    "    schedule_raw['weight'] = schedule_raw.apply(lambda x : weight(x['weeks_ago'], x['total_games'], max_games, decay), axis=1)\n",
    "    weight_shift = 100/schedule_raw['weight'].sum()\n",
    "    schedule_raw['weight'] = (schedule_raw['weight']*weight_shift)\n",
    "    \n",
    "    schedule = schedule_raw.drop(['team_loser', 'team_winner', 'games_loser', 'games_winner', 'location_adjustment', 'location', 'winner_pts', 'loser_pts','margin', 'weeks_ago', 'total_games'], axis=1)\n",
    "    return schedule\n",
    "\n",
    "def get_initial(schedule):\n",
    "\n",
    "    extras = schedule[['true_margin', 'weight']]\n",
    "    transform = schedule.drop(['true_margin', 'weight'], axis = 1)\n",
    "    winners = pd.get_dummies(transform, prefix='',prefix_sep = '', columns=['winner'])\n",
    "    losers = pd.get_dummies(transform, prefix='',prefix_sep = '', columns=['loser'])*-1\n",
    "    combined = pd.concat([winners,losers], axis = 1)\n",
    "    \n",
    "\n",
    "    x = combined.groupby(by = combined.columns, axis=1).sum().drop(['loser','winner'], axis = 1)\n",
    "    a = pd.DataFrame([1] * x.shape[0])\n",
    "    x = pd.concat([a, x.reset_index(drop=True)], axis = 1).to_numpy()\n",
    "    y = extras['true_margin'].to_numpy()\n",
    "    w = np.sqrt(extras['weight'].to_numpy())\n",
    "\n",
    "    regr = linear_model.LinearRegression(\n",
    "       fit_intercept = False, copy_X = True, n_jobs = -1\n",
    "    ).fit(x,y, sample_weight = w)\n",
    "\n",
    "    result=regr.coef_\n",
    "    result = result[1:] - result[1:].mean()\n",
    "    teams = combined.groupby(by = combined.columns, axis=1).sum().drop(['loser','winner'], axis = 1).columns.values\n",
    "    d = {'teams': teams, 'coefs': result}\n",
    "    r1_ratings = pd.DataFrame(data = d)\n",
    "\n",
    "    r1_ratings.sort_values(by=['coefs'], inplace=True, ascending=False)\n",
    "\n",
    "    schedule.set_index('winner', inplace=True, drop = False)\n",
    "    r1_ratings.set_index('teams', inplace=True, drop = False)\n",
    "    with_winner = schedule.join(r1_ratings, how='left').set_index('loser', drop = False)\n",
    "\n",
    "    with_ratings = with_winner.join(r1_ratings, how = 'left', lsuffix='_winner', rsuffix='_loser').drop(['teams_winner', 'teams_loser'], axis = 1)\n",
    "    with_ratings.reset_index(inplace = True, drop = True)\n",
    "    return with_ratings\n",
    "\n",
    "def get_rating(subject, initial):\n",
    "    with_ratings = initial[['winner', 'loser', 'true_margin', 'weight','coefs_winner', 'coefs_loser']]\n",
    "    \n",
    "    winner_subject = with_ratings.loc[(with_ratings['winner']==subject)] \n",
    "    loser_subject = with_ratings.loc[(with_ratings['loser']==subject)] \n",
    "    loser_subject['true_margin'] = -loser_subject['true_margin']\n",
    "\n",
    "    winner_subject.columns = ['team1', 'team2', 'true_margin', 'weight','rating_team1', 'rating_team2']\n",
    "    loser_subject.columns = ['team2', 'team1', 'true_margin', 'weight','rating_team2', 'rating_team1']\n",
    "\n",
    "    subject_set = pd.concat([winner_subject, loser_subject], ignore_index=True)\n",
    "    subject_set['y'] = subject_set['true_margin']+subject_set['rating_team2']\n",
    "    subject_set['x'] = 1\n",
    "    x = subject_set['x'].to_numpy()\n",
    "    y = subject_set['y'].to_numpy()\n",
    "    w = subject_set['weight'].to_numpy()\n",
    "\n",
    "    rating = np.dot(y,w)/np.dot(w,x)\n",
    "    return rating\n",
    "\n",
    "def get_teams(schedule):\n",
    "    return pd.concat([schedule['winner'], schedule['loser']], axis = 0, ignore_index=True).unique().tolist()\n",
    "\n",
    "def get_ratings(schedule):\n",
    "    initial = get_initial(schedule)\n",
    "    teams = get_teams(schedule)\n",
    "    output_list = list(map(lambda x: get_rating(x, initial), teams))\n",
    "    ratings = pd.DataFrame(list(zip(teams, output_list)), columns=['teams', 'ratings'])\n",
    "    return ratings.sort_values(\"ratings\", axis = 0, ascending = False)\n",
    "\n",
    "def get_error(schedule, ratings):\n",
    "    schedule.drop(['week'], inplace = True, axis = 1)\n",
    "    ratings.sort_values(by=['ratings'], inplace=True, ascending=False)\n",
    "\n",
    "    schedule.set_index('winner', inplace=True, drop = False)\n",
    "    ratings.set_index('teams', inplace=True, drop = False)\n",
    "    with_winner = schedule.join(ratings, how='left').set_index('loser', drop = False)\n",
    "\n",
    "    with_ratings = with_winner.join(ratings, how = 'left', lsuffix='_winner', rsuffix='_loser').drop(['teams_winner', 'teams_loser'], axis = 1)\n",
    "    with_ratings.reset_index(inplace = True, drop = True)\n",
    "    with_ratings['error'] = (with_ratings['true_margin'] - (with_ratings['ratings_winner'] - with_ratings['ratings_loser']))**2\n",
    "\n",
    "    with_ratings.drop(['true_margin','ratings_winner', 'ratings_loser'], inplace = True, axis = 1)\n",
    "\n",
    "    with_ratings2 = with_ratings.copy()\n",
    "\n",
    "    with_ratings.columns = ['team1', 'team2', 'weight', 'error']\n",
    "    with_ratings2.columns = ['team2', 'team1', 'weight', 'error']\n",
    "\n",
    "    error_set = (pd.concat([with_ratings, with_ratings2], ignore_index=True)).drop(['team2'], axis = 1)\n",
    "    ##need to factor in weight\n",
    "    error_sum = pd.DataFrame(error_set.groupby(by = 'team1', axis=0).apply(lambda x: (x.weight*x.error).sum()))\n",
    "    error_count = error_set.drop(['weight'], axis = 1).groupby(by = 'team1', axis=0).count()\n",
    "\n",
    "\n",
    "    error_total = error_sum.join(error_count, lsuffix = \"r\", rsuffix = \"l\")\n",
    "    error_total.reset_index(inplace = True)\n",
    "    error_total.columns = ['team', 'error', 'games']\n",
    "\n",
    "    error_total['rmse'] = (error_total['error']/error_total['games'])**0.5\n",
    "    error_total['psudo_sd'] = ((error_total['rmse']*error_total['games'])+9*12)/(error_total['games']+12)\n",
    "    error = error_total.drop(['error','games','rmse'], axis = 1)\n",
    "    return error\n",
    "\n",
    "def n_max(given_list, k, default = 0):\n",
    "    length = len(given_list)+1\n",
    "    if k >= length:\n",
    "        return default\n",
    "    given_list.sort()\n",
    "    return given_list[-k]\n",
    "\n",
    "def n_min(given_list, k, default = 0):\n",
    "    length = len(given_list)+1\n",
    "    if k >= length:\n",
    "        return default\n",
    "    given_list.sort()\n",
    "    return given_list[-(length - k)]\n",
    "\n",
    "class Team:\n",
    "    def __init__(self, name, victory, defeat):\n",
    "        self.name = name\n",
    "        self.victory = victory\n",
    "        self.defeat = defeat\n",
    "        \n",
    "    def get_wins(self):\n",
    "        return len(self.victory)\n",
    "    \n",
    "    def get_victories(self):\n",
    "        return self.victory\n",
    "    \n",
    "    def get_losses(self):\n",
    "        return len(self.defeat)\n",
    "    \n",
    "    def get_defeats(self):\n",
    "        return self.defeat\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Team: {self.name}, Victory: {self.victory}, Defeat: {self.defeat}\"\n",
    "    \n",
    "    \n",
    "def get_worster(year, week = 20):\n",
    "    url1 = 'https://www.sports-reference.com/cfb/years/'\n",
    "    url2 = '-schedule.html'\n",
    "    \n",
    "    url = url1+str(year)+url2\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    schedule = get_schedule(soup, week = week)\n",
    "    team_dict = {}\n",
    "    for i in get_teams(schedule):\n",
    "        victory = schedule.loc[(schedule['winner']==i)]['loser'].tolist()\n",
    "        defeat = schedule.loc[(schedule['loser']==i)]['winner'].tolist()\n",
    "        team_dict[i] = Team(i, victory, defeat)\n",
    "    team_list = get_teams(schedule)\n",
    "\n",
    "    team_df = pd.DataFrame(team_list, columns = ['team'])\n",
    "    team_df = team_df.assign(wins = list(map(lambda x: team_dict[x].get_wins(), get_teams(schedule))))\n",
    "    team_df = team_df.assign(losses = list(map(lambda x: team_dict[x].get_losses(), get_teams(schedule))))\n",
    "    team_df = team_df.assign(wins_from_1best = list(map(lambda y: max(list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),default=0), get_teams(schedule))))\n",
    "    team_df = team_df.assign(wins_from_1worst = list(map(lambda y: min(list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),default=0), get_teams(schedule))))\n",
    "\n",
    "    team_df = (pd.DataFrame(team_list, columns = ['team'])\n",
    "     .assign(wins = \n",
    "             list(map(lambda x: team_dict[x].get_wins(), get_teams(schedule))))\n",
    "     .assign(losses = \n",
    "             list(map(lambda x: team_dict[x].get_losses(), get_teams(schedule))))\n",
    "     .assign(wins_from_1best = \n",
    "             list(map(lambda y: max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_1worst = \n",
    "             list(map(lambda y: min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_2best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),2,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_2worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),2,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_3best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),3,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_3worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),3,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_4best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),4,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_4worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),4,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_5best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),5,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_5worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),5,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_6best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),6,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_6worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),6,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_7best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),7,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_7worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),7,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_8best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),8,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_8worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),8,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_9best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),9,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_9worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),9,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_10best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),10,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_10worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),10,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_11best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),11,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_11worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),11,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_12best = \n",
    "             list(map(lambda y: n_max(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_victories())),12,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "     .assign(wins_from_12worst = \n",
    "             list(map(lambda y: n_min(\n",
    "                 list(map(lambda x: team_dict[x].get_wins(), team_dict[y].get_defeats())),12,default=0)\n",
    "                      , get_teams(schedule)\n",
    "                     )))\n",
    "    )\n",
    "\n",
    "\n",
    "    team_df = (\n",
    "        team_df.sort_values(by = (['wins','losses',\n",
    "                                'wins_from_1best', 'wins_from_1worst',\n",
    "                                'wins_from_2best', 'wins_from_2worst',\n",
    "                                'wins_from_3best', 'wins_from_3worst',\n",
    "                                'wins_from_4best', 'wins_from_4worst',\n",
    "                                'wins_from_5best', 'wins_from_5worst',\n",
    "                                'wins_from_6best', 'wins_from_6worst',\n",
    "                                'wins_from_7best', 'wins_from_7worst',\n",
    "                                'wins_from_8best', 'wins_from_8worst',\n",
    "                                'wins_from_9best', 'wins_from_9worst',\n",
    "                                'wins_from_10best', 'wins_from_10worst',\n",
    "                                'wins_from_11best', 'wins_from_11worst',\n",
    "                                'wins_from_12best', 'wins_from_12worst']),\n",
    "                         axis=0, ascending=([False, True, \n",
    "                                             False, False, \n",
    "                                             False, False, \n",
    "                                             False, False, \n",
    "                                             False, False,\n",
    "                                             False, False, \n",
    "                                             False, False, \n",
    "                                             False, False, \n",
    "                                             False, False,\n",
    "                                             False, False, \n",
    "                                             False, False, \n",
    "                                             False, False, \n",
    "                                             False, False]) )\n",
    "    )\n",
    "    return team_df\n",
    "\n",
    "def combined(ratings, error):\n",
    "    error.set_index('team', drop = False, inplace = True) \n",
    "    rating_error = ratings.join(error, how = 'left', lsuffix='_l', rsuffix='_r').drop(['teams','team'], axis = 1).reset_index()\n",
    "    rating_error.columns = ['team','rating','psudo_sd']\n",
    "    return rating_error\n",
    "\n",
    "def error_hfa(x, url, week):\n",
    "    hfa = x \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    schedule = get_schedule(soup, hfa = hfa, decay = 0, week = week)\n",
    "    ratings = get_ratings(schedule)\n",
    "    return get_error(schedule, ratings)['psudo_sd'].sum()\n",
    "\n",
    "def error_decay(x, hfa, url, week):\n",
    "    decay = x \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    schedule = get_schedule(soup, hfa = hfa, decay = x, week = week)\n",
    "    ratings = get_ratings(schedule)\n",
    "    return get_error(schedule, ratings)['psudo_sd'].sum()\n",
    "\n",
    "def get_underwood(year, week = 20, hyperparameters = {}):\n",
    "    \n",
    "    url1 = 'https://www.sports-reference.com/cfb/years/'\n",
    "    url2 = '-schedule.html'\n",
    "    \n",
    "    url = url1+str(year)+url2\n",
    "    \n",
    "    if \"home_adv\" in hyperparameters:\n",
    "        hfa = hyperparameters[\"home_adv\"]\n",
    "    else: \n",
    "        result = minimize_scalar(error_hfa, args=(url, week), method='brent')\n",
    "        hfa = result['x'] \n",
    "        \n",
    "    if \"decay_rate\" in hyperparameters:\n",
    "        decay = hyperparameters[\"decay_rate\"]\n",
    "    else: \n",
    "        result = minimize_scalar(error_decay, bounds=(0,1), args=(hfa, url, week), method='bounded')\n",
    "        decay = result['x']\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    schedule = get_schedule(soup, hfa = hfa, decay = decay, week = week)\n",
    "    ratings = get_ratings(schedule)\n",
    "    error = get_error(schedule, ratings)\n",
    "\n",
    "    return combined(ratings, error)\n",
    "\n",
    "\n",
    "def get_graph_data(year, week = 20, hyperparameters = {}):\n",
    "\n",
    "    url1 = 'https://www.sports-reference.com/cfb/years/'\n",
    "    url2 = '-schedule.html'\n",
    "\n",
    "    url = url1+str(year)+url2\n",
    "\n",
    "    if \"home_adv\" in hyperparameters:\n",
    "        hfa = hyperparameters[\"home_adv\"]\n",
    "    else: \n",
    "        result = minimize_scalar(error_hfa, args=(url, week), method='brent')\n",
    "        hfa = result['x'] \n",
    "\n",
    "    if \"decay_rate\" in hyperparameters:\n",
    "        decay = hyperparameters[\"decay_rate\"]\n",
    "    else: \n",
    "        result = minimize_scalar(error_decay, bounds=(0,1), args=(hfa, url, week), method='bounded')\n",
    "        decay = result['x']\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    schedule = get_schedule(soup, hfa = hfa, decay = decay, week = week)\n",
    "    initial = get_initial(schedule)\n",
    "\n",
    "    winners = initial[['winner', 'coefs_winner']]\n",
    "    winners.columns = ['teams', 'initial_rating']\n",
    "    losers = initial[['loser', 'coefs_loser']]\n",
    "    losers.columns = ['teams', 'initial_rating']\n",
    "\n",
    "    initial_ratings = (\n",
    "        winners.append(losers, ignore_index=True, verify_integrity=False)\n",
    "     .drop_duplicates()\n",
    "     .sort_values(by = 'initial_rating', ascending = False)\n",
    "     .set_index('teams', drop = False))\n",
    "    ratings = get_ratings(schedule)\n",
    "\n",
    "    schedule.set_index('winner', inplace=True, drop = False)\n",
    "    with_winner = schedule.join(initial_ratings, how='left').set_index('loser', drop = False)\n",
    "\n",
    "    with_ratings = with_winner.join(initial_ratings, how = 'left', lsuffix='_winner', rsuffix='_loser').drop(['teams_winner', 'teams_loser'], axis = 1)\n",
    "    with_ratings.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    with_ratings2 = with_ratings.copy()\n",
    "    with_ratings2['true_margin'] = -with_ratings['true_margin']\n",
    "\n",
    "    with_ratings.columns = ['week', 'team1', 'team2', 'true_margin', 'weight', 'ratings_team1', 'ratings_team2']\n",
    "    with_ratings2.columns = ['week', 'team2', 'team1', 'true_margin', 'weight', 'ratings_team2', 'ratings_team1']\n",
    "\n",
    "    error_set = (pd.concat([with_ratings, with_ratings2], ignore_index=True))\n",
    "\n",
    "    graph_data = pd.DataFrame(columns =['week','team1', 'team2', 'ratings_team1', 'error'])\n",
    "\n",
    "    for j in get_teams(schedule):\n",
    "        subject = j\n",
    "        game_set = error_set[error_set['team1']==subject]\n",
    "        proposed = round((ratings[ratings['teams']==subject]['ratings'].values[0]),0)\n",
    "        rating_range = np.arange(proposed - 8, proposed + 8)\n",
    "\n",
    "        for i in rating_range:\n",
    "\n",
    "            game_set['ratings_team1'] = i\n",
    "            game_set['error'] = (game_set['weight']*(game_set['true_margin'] - \n",
    "                                                     (game_set['ratings_team1']-game_set['ratings_team2']))**2)\n",
    "            temp = game_set.drop(['true_margin', 'weight', 'ratings_team2'], axis = 1)\n",
    "            graph_data = graph_data.append(temp, ignore_index = True)\n",
    "            graph_data['error'] = round(graph_data['error'],2)\n",
    "\n",
    "    graph_data.columns=['week','team', 'opponent', 'hypothetical rating', 'error']\n",
    "\n",
    "    return graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f828fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://www.sports-reference.com/cfb/years/'\n",
    "year = 2022\n",
    "url2 = '-schedule.html'\n",
    "url = url1+str(year)+url2 \n",
    "\n",
    "fbs = pd.read_csv(os.getcwd() +\"\\\\FBS.csv\")\n",
    "\n",
    "\n",
    "week = 20\n",
    "\n",
    "hfa = minimize_scalar(error_hfa, args=(url, week), method='brent', tol=0.001)['x']\n",
    "decay = minimize_scalar(error_decay, bounds=(1/5,1), args=(hfa, url, week), method='bounded')['x']\n",
    "\n",
    "hyperparameters = {\n",
    "  \"home_adv\": hfa,\n",
    "  \"decay_rate\": decay\n",
    "}\n",
    "\n",
    "\n",
    "underwood = get_underwood(year, week = week, hyperparameters = hyperparameters)\n",
    "\n",
    "underwood = underwood[underwood['team'].isin(fbs['team'])].reset_index(drop = True)\n",
    "underwood.insert(loc=0, column='rank', value=range(1,132))\n",
    "\n",
    "underwood.columns = ['Rank', 'Team', 'Rating', 'Std Dev']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ec1ac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Std Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ohio State</td>\n",
       "      <td>30.943805</td>\n",
       "      <td>6.490292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>26.119211</td>\n",
       "      <td>7.118446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>24.215505</td>\n",
       "      <td>6.892906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>23.668892</td>\n",
       "      <td>6.548398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>22.571062</td>\n",
       "      <td>7.328509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>127</td>\n",
       "      <td>Akron</td>\n",
       "      <td>-11.356574</td>\n",
       "      <td>6.944619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>128</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>-11.798370</td>\n",
       "      <td>7.098981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>129</td>\n",
       "      <td>Colorado State</td>\n",
       "      <td>-13.085110</td>\n",
       "      <td>6.606215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>130</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>-14.906492</td>\n",
       "      <td>6.655957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>131</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>-17.136806</td>\n",
       "      <td>6.611008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank            Team     Rating   Std Dev\n",
       "0       1      Ohio State  30.943805  6.490292\n",
       "1       2         Georgia  26.119211  7.118446\n",
       "2       3         Alabama  24.215505  6.892906\n",
       "3       4        Michigan  23.668892  6.548398\n",
       "4       5       Tennessee  22.571062  7.328509\n",
       "..    ...             ...        ...       ...\n",
       "126   127           Akron -11.356574  6.944619\n",
       "127   128      New Mexico -11.798370  7.098981\n",
       "128   129  Colorado State -13.085110  6.606215\n",
       "129   130        Colorado -14.906492  6.655957\n",
       "130   131   Massachusetts -17.136806  6.611008\n",
       "\n",
       "[131 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "underwood"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
